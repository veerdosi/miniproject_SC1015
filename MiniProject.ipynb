{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qiW9Dhho1xMj"
   },
   "source": [
    "## Title: Early Prediction of Heart Failure Using Clinical Features\n",
    "\n",
    "### Problem Statement\n",
    "**Introduction**: Heart disease remains a leading cause of morbidity and mortality worldwide, posing significant public health challenges. Early detection of heart failure, a major form of heart disease, is critical for improving patient outcomes and managing healthcare resources efficiently.\n",
    "\n",
    "**Problem Statement**: Despite advancements in medical science, many individuals at risk of heart failure remain undiagnosed until the disease progresses to advanced stages. Traditional diagnostic methods can be invasive, expensive, and not universally accessible, creating a need for alternative early detection techniques.\n",
    "\n",
    "### Objectives\n",
    "To develop a predictive model that utilizes easily obtainable clinical features to identify individuals at high risk of heart failure, facilitating early intervention and potentially saving lives.\n",
    "\n",
    "### Dataset Description\n",
    "The dataset, titled “Heart Failure Prediction Dataset,” comprises medical records from patients, featuring variables such as age, sex, chest pain type, resting blood pressure, cholesterol levels, and more, culminating in a binary indicator of heart disease presence. This comprehensive dataset serves as the foundation for our predictive modeling.\n",
    "\n",
    "### Methodology\n",
    "**Data Preparation and Cleaning**: Initial steps involved handling missing values, encoding categorical variables, and normalizing continuous variables to prepare the data for analysis.\n",
    "\n",
    "**Exploratory Data Analysis (EDA)**: We examined the distribution and relationships among clinical variables to uncover patterns and correlations that could indicate heart failure risk.\n",
    "\n",
    "**Feature Engineering**: New features were derived to enhance the model's predictive capability, including interaction terms between clinically significant variables.\n",
    "\n",
    "**Model Development**: We applied several machine learning algorithms, such as Logistic Regression, Random Forest, and Gradient Boosting, optimizing them to achieve the best performance in predicting heart failure.\n",
    "\n",
    "**Evaluation and Optimization**: Models were evaluated using metrics like accuracy, precision, recall, F1 score, and ROC-AUC, with hyperparameter tuning performed to refine their predictive performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "eQUkSJUqxOM5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('heart.csv')\n",
    "\n",
    "# Check for missing values\n",
    "# print(df.isnull().sum())\n",
    "\n",
    "# Assuming minimal missing values, we'll drop rows with missing data for simplicity\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Encoding categorical variables and normalizing continuous ones\n",
    "categorical_features = ['Sex', 'ChestPainType', 'FastingBS', 'RestingECG', 'ExerciseAngina', 'ST_Slope']\n",
    "continuous_features = ['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), continuous_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Prepare the final dataset\n",
    "X = df.drop('HeartDisease', axis=1)\n",
    "y = df['HeartDisease']\n",
    "\n",
    "# Splitting dataset into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_xPFVQIE0LJS"
   },
   "outputs": [],
   "source": [
    "# Interaction Terms\n",
    "df['Age_Chol_Interact'] = df['Age'] * df['Cholesterol']\n",
    "df['Age_RestingBP_Interact'] = df['Age'] * df['RestingBP']\n",
    "\n",
    "# Polynomial Features for Age and MaxHR (considered outside of the pipeline for simplicity)\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "poly_features = poly.fit_transform(df[['Age', 'MaxHR']])\n",
    "poly_feature_names = poly.get_feature_names(['Age', 'MaxHR'])\n",
    "\n",
    "# Add polynomial features to the DataFrame\n",
    "for i, name in enumerate(poly_feature_names):\n",
    "    df[name] = poly_features[:, i]\n",
    "\n",
    "# Assuming the preprocessor and models are defined as before\n",
    "# Update continuous_features to include the new features\n",
    "continuous_features += ['Age_Chol_Interact', 'Age_RestingBP_Interact'] + list(poly_feature_names)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), continuous_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T0ij9B912toi"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Define the models and hyperparameters for grid search\n",
    "models_and_parameters = {\n",
    "    'LogisticRegression': (LogisticRegression(random_state=42),\n",
    "                           {'classifier__C': [0.1, 1, 10]}),\n",
    "    'RandomForestClassifier': (RandomForestClassifier(random_state=42),\n",
    "                               {'classifier__n_estimators': [100, 200],\n",
    "                                'classifier__max_depth': [None, 10, 20]}),\n",
    "    'GradientBoostingClassifier': (GradientBoostingClassifier(random_state=42),\n",
    "                                   {'classifier__n_estimators': [100, 200],\n",
    "                                    'classifier__learning_rate': [0.01, 0.1],\n",
    "                                    'classifier__max_depth': [3, 5]})\n",
    "}\n",
    "\n",
    "# Loop through models and parameters to fit and evaluate each\n",
    "for model_name, (model, params) in models_and_parameters.items():\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('classifier', model)])\n",
    "\n",
    "    grid_search = GridSearchCV(pipeline, params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(f\"{model_name} Best Parameters: {grid_search.best_params_}\")\n",
    "    print(f\"{model_name} Best Score: {grid_search.best_score_}\")\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"{model_name} Evaluation Metrics:\")\n",
    "    print(f\"Accuracy: {accuracy}\\nPrecision: {precision}\\nRecall: {recall}\\nF1 Score: {f1}\\nROC AUC: {roc_auc}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ECn1KI6R2NZK"
   },
   "source": [
    "### Results\n",
    "The developed models demonstrated promising capabilities in identifying individuals at risk of heart failure, with the Random Forest classifier showing particularly high performance across various metrics. Feature importance analysis highlighted key predictors of heart failure, providing valuable insights for clinical assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e-vtgArC5WaM"
   },
   "outputs": [],
   "source": [
    "!pip install reportlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PG0rGJhB5obA"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.platypus import Image\n",
    "import numpy as np\n",
    "\n",
    "def create_graphs(predictions):\n",
    "    # Line graph of predictions\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(predictions, label='Heart Failure Risk Score')\n",
    "    plt.title('Heart Failure Risk Over Time')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Risk Score')\n",
    "    plt.legend()\n",
    "    plt.savefig('line_graph.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Pie chart of overall prediction\n",
    "    risk = np.mean(predictions)\n",
    "    labels = 'Risk of Heart Failure', 'No Risk of Heart Failure'\n",
    "    sizes = [risk, 1-risk]\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=140)\n",
    "    plt.title('Overall Heart Failure Risk')\n",
    "    plt.savefig('pie_chart.png')\n",
    "\n",
    "def generate_report(user_info, predictions):\n",
    "    create_graphs(predictions)\n",
    "\n",
    "    doc = SimpleDocTemplate(\"heart_failure_report.pdf\", pagesize=letter)\n",
    "    styles = getSampleStyleSheet()\n",
    "    Story = []\n",
    "\n",
    "    Story.append(Paragraph(\"Heart Failure Prediction Report\", styles['Title']))\n",
    "    Story.append(Spacer(1, 12))\n",
    "\n",
    "    # User Information in bullet points\n",
    "    Story.append(Paragraph(\"User Information:\", styles['Heading2']))\n",
    "    for key, value in user_info.items():\n",
    "        Story.append(Paragraph(f\"- {key}: {value}\", styles['Normal']))\n",
    "    Story.append(Spacer(1, 12))\n",
    "\n",
    "    # Predicted Risk Scores\n",
    "    prediction_text = ', '.join([f\"{score:.2f}\" for score in predictions])\n",
    "    Story.append(Paragraph(f\"Predicted Risk Scores: {prediction_text}\", styles['Normal']))\n",
    "    Story.append(Spacer(1, 12))\n",
    "\n",
    "    # User-friendly paragraph explaining the output\n",
    "    avg_prediction = np.mean(predictions)\n",
    "    risk_level = \"high\" if avg_prediction > 0.5 else \"low\"\n",
    "    explanation_text = f\"Based on the provided information, the model assesses a {risk_level} risk of heart failure. \"\n",
    "    explanation_text += \"These predictions are estimations and should not replace professional medical advice. \"\n",
    "    explanation_text += \"Consulting with a healthcare provider is recommended for an accurate assessment and guidance.\"\n",
    "    Story.append(Paragraph(explanation_text, styles['Normal']))\n",
    "    Story.append(Spacer(1, 12))\n",
    "\n",
    "    # Include Graphs (As Images)\n",
    "    Story.append(Paragraph(\"Risk Score Over Time:\", styles['Heading2']))\n",
    "    Story.append(Image('line_graph.png', width=400, height=200))\n",
    "    Story.append(Spacer(1, 12))\n",
    "\n",
    "    Story.append(Paragraph(\"Overall Risk Assessment:\", styles['Heading2']))\n",
    "    Story.append(Image('pie_chart.png', width=400, height=200))\n",
    "    Story.append(Spacer(1, 12))\n",
    "\n",
    "    doc.build(Story)\n",
    "\n",
    "\n",
    "generate_report(user_info, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K7FxP13T6x4v"
   },
   "outputs": [],
   "source": [
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EXK0QzxZ6kmD"
   },
   "outputs": [],
   "source": [
    "st.title('Heart Failure Prediction')\n",
    "\n",
    "# Input data from the user\n",
    "age = st.number_input('Age', min_value=1, max_value=120, value=30)\n",
    "sex = st.selectbox('Sex', options=['Male', 'Female'])\n",
    "resting_bp = st.number_input('Resting Blood Pressure', min_value=50, max_value=200, value=120)\n",
    "cholesterol = st.number_input('Cholesterol', min_value=100, max_value=400, value=200)\n",
    "resting_ecg = st.selectbox('Resting ECG', options=['Normal', 'ST', 'LVH'])\n",
    "\n",
    "# Assuming model expects these inputs in this order\n",
    "inputs = [age, 0 if sex == 'Male' else 1, resting_bp, cholesterol, 0 if resting_ecg == 'Normal' else 1 if resting_ecg == 'ST' else 2]\n",
    "\n",
    "if st.button('Predict'):\n",
    "    predictions = predict_risk(inputs)\n",
    "\n",
    "    # Displaying the prediction\n",
    "    st.write(f'Prediction: {\"High Risk\" if predictions[0] == 1 else \"Low Risk\"}')\n",
    "\n",
    "    # For demonstration, using random predictions over time\n",
    "    predictions_over_time = np.random.rand(10)\n",
    "    create_graphs(predictions_over_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PYACaAOD5VRy"
   },
   "source": [
    "### Conclusion\n",
    "The project successfully established a predictive model capable of early heart failure detection based on clinical features. This model can serve as a tool for healthcare professionals to prioritize high-risk patients for further testing and intervention, potentially reducing heart failure incidences and improving patient outcomes.\n",
    "\n",
    "### Future Work\n",
    "Further research could explore integrating additional data sources, such as genetic markers or lifestyle factors, to enhance the model's accuracy. Moreover, deploying the model into a real-world clinical setting represents an exciting frontier for transforming heart disease diagnosis and treatment strategies.\n",
    "\n",
    "### Implementation Notes\n",
    "Throughout the analysis and model development process, detailed documentation and comments in the code ensure clarity and reproducibility of results. These notes serve as a guide for other researchers or practitioners wishing to apply or extend this work."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
